{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6006778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# proxy for download in cloud server\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db42e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets sentence_transformers setfit pandas nlpcda openpyxl optuna gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c5b701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "from setfit import SetFitModel, SetFitTrainer, sample_dataset\n",
    "import pandas as pd\n",
    "from datasets import Dataset, ClassLabel, Features, Value\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a425392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init(params):\n",
    "    params = params or {}\n",
    "    max_iter = params.get(\"max_iter\", 100)\n",
    "    solver = params.get(\"solver\", \"liblinear\")\n",
    "    params = {\n",
    "        \"head_params\": {\n",
    "            \"max_iter\": max_iter,\n",
    "            \"solver\": solver,\n",
    "        }\n",
    "    }\n",
    "    return SetFitModel.from_pretrained(\"./DMetaSoul_sbert-chinese-general-v2\", **params)\n",
    "\n",
    "\n",
    "def hp_space(trial):  # Training parameters just for demonstration\n",
    "    return {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True),\n",
    "        \"num_epochs\": trial.suggest_int(\"num_epochs\", 1, 2),\n",
    "        \"batch_size\": trial.suggest_categorical(\"batch_size\", [16, 32]),\n",
    "        \"seed\": trial.suggest_int(\"seed\", 1, 40),\n",
    "        \"num_iterations\": trial.suggest_categorical(\"num_iterations\", [5, 10, 20]),\n",
    "        \"max_iter\": trial.suggest_int(\"max_iter\", 50, 300),\n",
    "        \"solver\": trial.suggest_categorical(\n",
    "            \"solver\", [\"newton-cg\", \"lbfgs\", \"liblinear\"]\n",
    "        ),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350a31fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def compute_f1(y_pred, y_test):\n",
    "\n",
    "    return {\"f1\": f1_score(y_test, y_pred, average=\"binary\", zero_division=1.0)}\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def compute_f1_a(y_pred, y_test):\n",
    "\n",
    "    return {\"f1\": f1_score(y_test, y_pred, average=\"macro\", zero_division=1.0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a07b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = [\n",
    "    \"Practical barriers to vaccination (-)\",\n",
    "    \"Perceived barriers to accepting vaccines (-)\",\n",
    "    \"Perceived benefits (+)\",\n",
    "    \"Misinformation (-)\",\n",
    "    \"Perceived Disease Risk (+)\",\n",
    "    \"Social norms  cues to action (+)\",\n",
    "    \"Attitude\",\n",
    "]\n",
    "\n",
    "# load data\n",
    "train_all, test_all = pd.read_csv('train1.csv'), pd.read_csv('test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e398650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "for col in col_list[:]:\n",
    "\n",
    "    train_data, test_data = train_all.loc[:,['content',col]], test_all.loc[:,['content',col]]\n",
    "    train_dataset = Dataset.from_pandas(train_data)\n",
    "    test_dataset = Dataset.from_pandas(test_data)\n",
    "\n",
    "    if col == 'attitude':\n",
    "        trainer = SetFitTrainer(\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        model_init=model_init,\n",
    "        metric=compute_f1_a,\n",
    "        column_mapping={\"content\": \"text\", col: \"label\"},\n",
    "    )\n",
    "    else:\n",
    "        trainer = SetFitTrainer(\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=test_dataset,\n",
    "            model_init=model_init,\n",
    "            metric=compute_f1,\n",
    "            column_mapping={\"content\": \"text\", col: \"label\"},\n",
    "        )\n",
    "    # search for the best model\n",
    "    best_run = trainer.hyperparameter_search(\n",
    "        direction=\"maximize\", hp_space=hp_space, n_trials=3\n",
    "    )\n",
    "    \n",
    "    trainer.apply_hyperparameters(best_run.hyperparameters, final_model=True)\n",
    "    trainer.train()\n",
    "\n",
    "    metrics = trainer.evaluate()\n",
    "\n",
    "    trainer.model.save_pretrained(f'./model/{col}')\n",
    "\n",
    "    with open(\"results.txt\", \"a\") as file:\n",
    "        file.write(\"---\" * 20)\n",
    "        file.write(f\"\\n{datetime.datetime.now()}\")\n",
    "        file.write(f\"\\nlabel: {col}\\n\")\n",
    "        file.write(f\"metrics: {metrics}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
